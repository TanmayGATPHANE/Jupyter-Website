{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print('testttt')"
      ],
      "outputs": [
        {
          "text": "test\nüîç Current namespace variables: {'np': 'module', 'numpy': 'module', 'pd': 'module', 'pandas': 'module', 'plt': 'module', 'matplotlib': 'module', 'data': 'ndarray', 'df': 'DataFrame', 'sample_data': 'list', 'outlier_indices': 'list', 'outlier_indices_z': 'list', 'requests': 'module', 'json': 'module'}\n\n[Executed in 0.1ms]"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Examplefrom sklearn.datasets import make_classificationfrom sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import accuracy_score, classification_reportimport numpy as npclass SimpleMLModel:    def __init__(self, n_samples=1000, n_features=20, n_classes=2):        self.n_samples = n_samples        self.n_features = n_features        self.n_classes = n_classes        self.model = None        self.X_train = None        self.X_test = None        self.y_train = None        self.y_test = None        def generate_data(self):        \"\"\"Generate synthetic dataset\"\"\"        print(f\"Generating {self.n_samples} samples with {self.n_features} features...\")                X, y = make_classification(            n_samples=self.n_samples,            n_features=self.n_features,            n_classes=self.n_classes,            n_redundant=5,            n_informative=15,            random_state=42        )                self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(            X, y, test_size=0.2, random_state=42        )                print(f\"Training set size: {len(self.X_train)}\")        print(f\"Test set size: {len(self.X_test)}\")        def train_model(self):        \"\"\"Train Random Forest model\"\"\"        print(\"Training Random Forest model...\")                self.model = RandomForestClassifier(            n_estimators=100,            random_state=42,            max_depth=10        )                self.model.fit(self.X_train, self.y_train)        print(\"Model training completed!\")        def evaluate_model(self):        \"\"\"Evaluate model performance\"\"\"        if self.model is None:            print(\"Model not trained yet!\")            return                # Predictions        y_pred = self.model.predict(self.X_test)                # Accuracy        accuracy = accuracy_score(self.y_test, y_pred)        print(f\"Model Accuracy: {accuracy:.4f}\")                # Classification report        print(\"\\nClassification Report:\")        print(classification_report(self.y_test, y_pred))                # Feature importance        feature_importance = self.model.feature_importances_        top_features = np.argsort(feature_importance)[-5:][::-1]                print(f\"\\nTop 5 Most Important Features:\")        for i, feature_idx in enumerate(top_features):            print(f\"{i+1}. Feature {feature_idx}: {feature_importance[feature_idx]:.4f}\")        def predict_sample(self, sample_data=None):        \"\"\"Make prediction on a sample\"\"\"        if self.model is None:            print(\"Model not trained yet!\")            return                if sample_data is None:            # Use first test sample            sample_data = self.X_test[0].reshape(1, -1)                prediction = self.model.predict(sample_data)        probability = self.model.predict_proba(sample_data)                print(f\"Prediction: Class {prediction[0]}\")        print(f\"Probability: {probability[0]}\")def main():    \"\"\"Main execution function\"\"\"    print(\"Machine Learning Pipeline Demo\")    print(\"=\" * 40)        # Initialize model    ml_model = SimpleMLModel(n_samples=1000, n_features=20)        # Generate data    ml_model.generate_data()        # Train model    ml_model.train_model()        # Evaluate model    ml_model.evaluate_model()        # Make sample prediction    print(\"\\nSample Prediction:\")    print(\"-\" * 20)    ml_model.predict_sample()if __name__ == \"__main__\":    main()"
      ],
      "outputs": [
        {
          "text": "Machine Learning Pipeline Demo\n========================================\nGenerating 1000 samples with 20 features...\nTraining set size: 800\nTest set size: 200\nTraining Random Forest model...\nModel training completed!\nModel Accuracy: 0.9000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.90      0.90       106\n           1       0.89      0.90      0.89        94\n\n    accuracy                           0.90       200\n   macro avg       0.90      0.90      0.90       200\nweighted avg       0.90      0.90      0.90       200\n\n\nTop 5 Most Important Features:\n1. Feature 12: 0.1167\n2. Feature 2: 0.0835\n3. Feature 5: 0.0704\n4. Feature 6: 0.0584\n5. Feature 17: 0.0543\n\nSample Prediction:\n--------------------\nPrediction: Class 0\nProbability: [0.95798936 0.04201064]\nüîç Current namespace variables: {'np': 'module', 'numpy': 'module', 'pd': 'module', 'pandas': 'module', 'plt': 'module', 'matplotlib': 'module', 'data': 'ndarray', 'df': 'DataFrame', 'sample_data': 'list', 'outlier_indices': 'list', 'outlier_indices_z': 'list', 'requests': 'module', 'json': 'module'}\n\n[Executed in 447.6ms]"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Analysis Utilities# Collection of utility functions for data analysisimport pandas as pdimport numpy as npfrom typing import List, Dict, Anydef load_csv_data(file_path: str) -> pd.DataFrame:    \"\"\"    Load CSV data with error handling        Args:        file_path: Path to the CSV file            Returns:        pandas DataFrame with the loaded data    \"\"\"    try:        df = pd.read_csv(file_path)        print(f\"Successfully loaded {len(df)} rows and {len(df.columns)} columns\")        return df    except Exception as e:        print(f\"Error loading CSV: {e}\")        return pd.DataFrame()def basic_stats(df: pd.DataFrame, column: str) -> Dict[str, float]:    \"\"\"    Calculate basic statistics for a column        Args:        df: pandas DataFrame        column: Column name to analyze            Returns:        Dictionary with basic statistics    \"\"\"    if column not in df.columns:        print(f\"Column '{column}' not found in DataFrame\")        return {}        stats = {        'mean': df[column].mean(),        'median': df[column].median(),        'std': df[column].std(),        'min': df[column].min(),        'max': df[column].max(),        'count': len(df[column])    }        return statsdef detect_outliers(data: List[float], method: str = 'iqr') -> List[int]:    \"\"\"    Detect outliers in numerical data        Args:        data: List of numerical values        method: Method to use ('iqr' or 'zscore')            Returns:        List of indices where outliers are found    \"\"\"    outliers = []        if method == 'iqr':        q1 = np.percentile(data, 25)        q3 = np.percentile(data, 75)        iqr = q3 - q1        lower_bound = q1 - 1.5 * iqr        upper_bound = q3 + 1.5 * iqr                outliers = [i for i, x in enumerate(data)                    if x < lower_bound or x > upper_bound]        elif method == 'zscore':        mean = np.mean(data)        std = np.std(data)        z_scores = [(x - mean) / std for x in data]        outliers = [i for i, z in enumerate(z_scores) if abs(z) > 3]        return outliers# Example usageif __name__ == \"__main__\":    # Generate sample data    sample_data = np.random.normal(0, 1, 1000).tolist()        # Add some outliers    sample_data.extend([10, -8, 12, -9])        # Detect outliers    outlier_indices = detect_outliers(sample_data, method='iqr')    print(f\"Found {len(outlier_indices)} outliers using IQR method\")        outlier_indices_z = detect_outliers(sample_data, method='zscore')    print(f\"Found {len(outlier_indices_z)} outliers using Z-score method\")"
      ],
      "outputs": [
        {
          "text": "Found 8 outliers using IQR method\nFound 4 outliers using Z-score method\nüîç Current namespace variables: {'np': 'module', 'numpy': 'module', 'pd': 'module', 'pandas': 'module', 'plt': 'module', 'matplotlib': 'module', 'data': 'ndarray', 'df': 'DataFrame', 'sample_data': 'list', 'outlier_indices': 'list', 'outlier_indices_z': 'list', 'requests': 'module', 'json': 'module'}\n\n[Executed in 3.3ms]"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}